{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from early_stopping import EarlyStopping\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn as nn\n",
    "\n",
    "from Custom_Dataset import NewDataset\n",
    "from lenet import Lenet\n",
    "from infogan_layers import ConvTranspose2d,Linear\n",
    "from InfoGAN import InfoGAN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's start building the GAN\n",
    "# But first, we're going to redefine Conv2D and Linear with our own initialisations\n",
    "# We're going to use Glorot (aka Xavier) uniform init for all weights\n",
    "# And we will use zero init for all biases\n",
    "\n",
    "c1_len = 10 # Multinomial\n",
    "c2_len = 2 # Gaussian\n",
    "c3_len = 2 # Bernoulli\n",
    "z_len = 114 # Noise vector length\n",
    "embedding_len = 128\n",
    "\n",
    "class Conv2d(nn.Conv2d):\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(6 / ((self.in_channels  + self.out_channels) * np.prod(self.kernel_size)))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "class ConvTranspose2d(nn.ConvTranspose2d):\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(6 / ((self.in_channels  + self.out_channels) * np.prod(self.kernel_size)))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "class Linear(nn.Linear):\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(6 / (self.in_features + self.out_features))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = Linear(z_len + c1_len + c2_len + c3_len, 1024)\n",
    "        self.fc2 = Linear(1024, 7 * 7 * 128)\n",
    "\n",
    "        self.convt1 = ConvTranspose2d(128, 64, kernel_size = 4, stride = 2, padding = 1)\n",
    "        self.convt2 = ConvTranspose2d(64, 1, kernel_size = 4, stride = 2, padding = 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(7 * 7 * 128)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x))).view(-1, 128, 7, 7)\n",
    "\n",
    "        x = F.relu(self.bn3(self.convt1(x)))\n",
    "        x = self.convt2(x)\n",
    "\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = Conv2d(1, 64, kernel_size = 4, stride = 2, padding = 1) # 28 x 28 -> 14 x 14\n",
    "        self.conv2 = Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1) # 14 x 14 -> 7 x 7\n",
    "\n",
    "        self.fc1 = Linear(128 * 7 ** 2, 1024)\n",
    "        self.fc2 = Linear(1024, 1)\n",
    "        self.fc1_q = Linear(1024, embedding_len)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        self.bn_q1 = nn.BatchNorm1d(embedding_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.bn1(self.conv2(x))).view(-1, 7 ** 2 * 128)\n",
    "\n",
    "        x = F.leaky_relu(self.bn2(self.fc1(x)))\n",
    "        return self.fc2(x), F.leaky_relu(self.bn_q1(self.fc1_q(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infogan_gen = Generator().to(device)\n",
    "infogan_dis = Discriminator().to(device)\n",
    "G = InfoGAN(infogan_gen, infogan_dis, embedding_len, z_len, c1_len, c2_len, c3_len, device)\n",
    "G.load('../../utils/trained_models/infogan_100_z_114/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dict = {}\n",
    "z_dict = G.get_z(c1_len * 3000, sequential = True)\n",
    "gan_input = torch.cat([z_dict[k] for k in z_dict.keys()], dim =1)\n",
    "gan_input = Variable(gan_input.to(device), requires_grad= True)\n",
    "out_gen = G.gen(gan_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(image_1[:50].detach().cpu(), nrow= 10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(out_gen,'train_images_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = torch.cat((torch.load('train_images_1'),torch.load('train_images_2')),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.LongTensor([0,1,2,3,4,5,6,7,8,9]*6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels,'labels_latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('train_images')\n",
    "train_labels = torch.load('labels_latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(image_1[:50].detach().cpu(), nrow= 10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "labels[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = NewDataset(image_1 ,labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./newmnist',transform=transform,train=False,download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0][0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 22\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed )\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cnn_model = Lenet()\n",
    "full_cnn_model.load_state_dict(torch.load('../trained_models/cnn_lenet_28_sigmoid.pt',map_location='cuda:0'))\n",
    "full_cnn_model.eval()\n",
    "full_cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = []\n",
    "for images_new,_ in train_loader:\n",
    "    out = F.softmax(full_cnn_model(images_new.to(device)),dim=1)\n",
    "    _,labels = torch.max(out.data.cpu(), 1)\n",
    "    labels_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  torch.stack(labels_list).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(labels,'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = NewDataset(image_1 ,labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./newmnist',transform=transform,train=False,download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(image_1[:50].detach().cpu(), nrow= 10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "labels[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = image_1[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cnn_model = Lenet()\n",
    "full_cnn_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(full_cnn_model.parameters(), lr=learning_rate,amsgrad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(60):\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    full_cnn_model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = full_cnn_model (images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "    \n",
    "    full_cnn_model.eval()\n",
    "    accuracy_list = []\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        outputs = full_cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = labels.size(0)\n",
    "        correct = (predicted == labels).sum()\n",
    "        accuracy = 100 * (float(correct) /float( total))\n",
    "        accuracy_list.append(accuracy)\n",
    "        test_loss_list.append(loss.item())\n",
    "    final_accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "    traininig_loss = sum(train_loss_list)/len(train_loss_list)\n",
    "    testing_loss = sum(test_loss_list)/len(test_loss_list)\n",
    "    print('Epoch: {}. TrainLoss: {}. TestLoss: {}. Accuracy: {}'.format(epoch, traininig_loss,testing_loss, final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
