{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from early_stopping import EarlyStopping\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn as nn\n",
    "\n",
    "from Custom_Dataset import NewDataset\n",
    "from lenet import Lenet\n",
    "from infogan_new import Generator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/infogan_new'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f9b250f288f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/infogan_new'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'netG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/infogan_new'"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('models/infogan',map_location=device)\n",
    "params = state_dict['params']\n",
    "G = Generator()\n",
    "G.load_state_dict(state_dict['netG'])\n",
    "\n",
    "full_cnn_model = Lenet()\n",
    "full_cnn_model.load_state_dict(torch.load('models/cnn_lenet_28_sigmoid.pt',map_location='cuda:0'))\n",
    "full_cnn_model.eval()\n",
    "full_cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_z(length, sequential = False):\n",
    "#     weights = torch.Tensor([0.1] * 10)\n",
    "\n",
    "#     z = {}\n",
    "#     if z_len:\n",
    "#         z['z'] = Variable(torch.randn(length, z_len)).to(device)\n",
    "\n",
    "#     if c1_len:\n",
    "#         if sequential:\n",
    "#             cat_noise = Variable(torch.arange(0, c1_len).repeat(length // c1_len).long()).to(device)\n",
    "#         else:\n",
    "#             cat_noise = Variable(torch.multinomial(weights, num_samples = length, replacement = True)).to(device).view(-1)\n",
    "#         onehot_noise = Variable(torch.zeros(length, c1_len)).to(device)\n",
    "#         onehot_noise.data.scatter_(1, cat_noise.data.view(-1, 1), 1)\n",
    "#         z['cat'] = onehot_noise\n",
    "\n",
    "#     if c2_len:\n",
    "#         #z['con'] = Variable(torch.randn(length, c2_len)).cuda()\n",
    "#         z['con'] = Variable(torch.rand(length, self.c2_len)).to(device) * 2 - 1\n",
    "\n",
    "#     if c3_len:\n",
    "#         z['bin'] = Variable(torch.bernoulli(0.5 * torch.ones(length, c3_len))).to(device).float()\n",
    "\n",
    "#     return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = {}\n",
    "# length = 100\n",
    "# z_len = 62\n",
    "# c1_len = 10\n",
    "# c2_len = 0\n",
    "# c3_len = 0\n",
    "# z_dict = get_z(c1_len*6000, sequential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan_input = torch.cat([z_dict[k] for k in z_dict.keys()], dim =1)\n",
    "# gan_input = Variable(gan_input.to(device), requires_grad= True)\n",
    "# gan_input = torch.cat([z_dict[k] for k in z_dict.keys()], dim =1)\n",
    "# gan_input = gan_input.view(60000,72,1,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.eval().to(device)\n",
    "# generated_img1 = G(gan_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_img = torchvision.utils.make_grid(generated_img1[:50].detach().cpu(), nrow= 10)\n",
    "# plt.imshow(grid_img.permute(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.LongTensor([9,4,7,8,2,0,1,6,3,5]*6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(generated_img1,'infogantraindata')\n",
    "# torch.save(labels,'infoganlabels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data = torch.load('infogan_traindata',map_location='cuda:0').data\n",
    "labels = torch.LongTensor([0,1,2,3,4,5,6,7,8,9]*6000)\n",
    "# mnist_2 = torch.load('wgan_mnist_part2',map_location='cuda:1')\n",
    "# mnist_infogan = torch.cat((mnist_1,mnist_2),dim=0)\n",
    "# grid_img = torchvision.utils.make_grid(mnist_wgan[:50].detach().cpu(), nrow= 10)\n",
    "# plt.imshow(grid_img.permute(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(mnist_train_data[:50].detach().cpu(), nrow= 10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "print(labels[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = NewDataset(mnist_train_data, labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./newmnist',transform=transform,train=False,download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset[0][0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (images, labels) in enumerate(train_loader):\n",
    "#     images = Variable(images).to(device)\n",
    "#     labels = Variable(labels).to(device)\n",
    "#     outputs = full_cnn_model(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total = labels.size(0)\n",
    "#     correct = (predicted == labels).sum()\n",
    "#     accuracy = 100 * (float(correct) /float( total))\n",
    "#     accuracy_list.append(accuracy)\n",
    "# final_accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "\n",
    "# print('Accuracy: {}'.format(final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 22\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed )\n",
    "torch.cuda.manual_seed(seed )\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cnn_model = Lenet()\n",
    "full_cnn_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(full_cnn_model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(60):\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    full_cnn_model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = full_cnn_model (images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "    \n",
    "    full_cnn_model.eval()\n",
    "    accuracy_list = []\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        outputs = full_cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = labels.size(0)\n",
    "        correct = (predicted == labels).sum()\n",
    "        accuracy = 100 * (float(correct) /float( total))\n",
    "        accuracy_list.append(accuracy)\n",
    "        test_loss_list.append(loss.item())\n",
    "    final_accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "    traininig_loss = sum(train_loss_list)/len(train_loss_list)\n",
    "    testing_loss = sum(test_loss_list)/len(test_loss_list)\n",
    "    print('Epoch: {}. TrainLoss: {}. TestLoss: {}. Accuracy: {}'.format(epoch, traininig_loss,testing_loss, final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
