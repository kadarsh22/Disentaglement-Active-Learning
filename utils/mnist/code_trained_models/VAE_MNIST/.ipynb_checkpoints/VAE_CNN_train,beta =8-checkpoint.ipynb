{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fecc2dd8f90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "log_interval =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 1\n",
    "beta = 8\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.have_cuda = False\n",
    "        self.nz = nz\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # input is (nc) x 28 x 28\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 14 x 14\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 7 x 7\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1024, 4, 1, 0, bias=False),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     1024, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     nc, 4, 2, 1, bias=False),\n",
    "            # nn.BatchNorm2d(ngf),\n",
    "            # nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            # nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            # nn.Tanh()\n",
    "            nn.Sigmoid()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc21 = nn.Linear(512, nz)\n",
    "        self.fc22 = nn.Linear(512, nz)\n",
    "\n",
    "        self.fc3 = nn.Linear(nz, 512)\n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        conv = self.encoder(x);\n",
    "        # print(\"encode conv\", conv.size())\n",
    "        h1 = self.fc1(conv.view(-1, 1024))\n",
    "        # print(\"encode h1\", h1.size())\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        deconv_input = self.fc4(h3)\n",
    "        # print(\"deconv_input\", deconv_input.size())\n",
    "        deconv_input = deconv_input.view(-1,1024,1,1)\n",
    "        # print(\"deconv_input\", deconv_input.size())\n",
    "        return self.decoder(deconv_input)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x\", x.size())\n",
    "        mu, logvar = self.encode(x)\n",
    "        # print(\"mu, logvar\", mu.size(), logvar.size())\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "            # print(\"z\", z.size())\n",
    "        decoded = self.decode(z)\n",
    "        # print(\"decoded\", decoded.size())\n",
    "        return decoded, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(20).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + beta*KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % args.log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader),\n",
    "#                 loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "         \n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kadarsh22/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 209.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kadarsh22/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([96, 784])) that is different to the input size (torch.Size([96, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 192.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kadarsh22/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average loss: 186.0133\n",
      "====> Test set loss: 181.4718\n",
      "====> Epoch: 3 Average loss: 180.7536\n",
      "====> Test set loss: 178.1478\n",
      "====> Epoch: 4 Average loss: 177.9415\n",
      "====> Test set loss: 176.9408\n",
      "====> Epoch: 5 Average loss: 176.6947\n",
      "====> Test set loss: 176.2815\n",
      "====> Epoch: 6 Average loss: 175.7234\n",
      "====> Test set loss: 175.3635\n",
      "====> Epoch: 7 Average loss: 175.1429\n",
      "====> Test set loss: 174.7929\n",
      "====> Epoch: 8 Average loss: 174.6132\n",
      "====> Test set loss: 173.8151\n",
      "====> Epoch: 9 Average loss: 174.3576\n",
      "====> Test set loss: 173.7927\n",
      "====> Epoch: 10 Average loss: 173.9794\n",
      "====> Test set loss: 174.0310\n",
      "====> Epoch: 11 Average loss: 173.6355\n",
      "====> Test set loss: 173.2278\n",
      "====> Epoch: 12 Average loss: 173.3578\n",
      "====> Test set loss: 173.0972\n",
      "====> Epoch: 13 Average loss: 173.0396\n",
      "====> Test set loss: 172.7270\n",
      "====> Epoch: 14 Average loss: 172.9665\n",
      "====> Test set loss: 172.4269\n",
      "====> Epoch: 15 Average loss: 172.7390\n",
      "====> Test set loss: 172.8256\n",
      "====> Epoch: 16 Average loss: 172.5273\n",
      "====> Test set loss: 172.4225\n",
      "====> Epoch: 17 Average loss: 172.4957\n",
      "====> Test set loss: 171.7304\n",
      "====> Epoch: 18 Average loss: 172.1397\n",
      "====> Test set loss: 171.9109\n",
      "====> Epoch: 19 Average loss: 172.1182\n",
      "====> Test set loss: 172.0557\n",
      "====> Epoch: 20 Average loss: 171.8344\n",
      "====> Test set loss: 171.8073\n",
      "====> Epoch: 21 Average loss: 171.9905\n",
      "====> Test set loss: 171.3989\n",
      "====> Epoch: 22 Average loss: 171.8089\n",
      "====> Test set loss: 172.2238\n",
      "====> Epoch: 23 Average loss: 171.6544\n",
      "====> Test set loss: 171.5782\n",
      "====> Epoch: 24 Average loss: 171.5546\n",
      "====> Test set loss: 171.1839\n",
      "====> Epoch: 25 Average loss: 171.6361\n",
      "====> Test set loss: 171.2134\n",
      "====> Epoch: 26 Average loss: 171.3089\n",
      "====> Test set loss: 170.9811\n",
      "====> Epoch: 27 Average loss: 171.2513\n",
      "====> Test set loss: 170.7126\n",
      "====> Epoch: 28 Average loss: 171.1246\n",
      "====> Test set loss: 171.1838\n",
      "====> Epoch: 29 Average loss: 171.0730\n",
      "====> Test set loss: 170.7306\n",
      "====> Epoch: 30 Average loss: 170.9686\n",
      "====> Test set loss: 170.8057\n",
      "====> Epoch: 31 Average loss: 170.9879\n",
      "====> Test set loss: 171.2466\n",
      "====> Epoch: 32 Average loss: 170.8344\n",
      "====> Test set loss: 170.7846\n",
      "====> Epoch: 33 Average loss: 170.7717\n",
      "====> Test set loss: 170.6529\n",
      "====> Epoch: 34 Average loss: 170.7947\n",
      "====> Test set loss: 170.8542\n",
      "====> Epoch: 35 Average loss: 170.5712\n",
      "====> Test set loss: 170.7262\n",
      "====> Epoch: 36 Average loss: 170.6831\n",
      "====> Test set loss: 170.8103\n",
      "====> Epoch: 37 Average loss: 170.6152\n",
      "====> Test set loss: 170.8740\n",
      "====> Epoch: 38 Average loss: 170.4415\n",
      "====> Test set loss: 170.7394\n",
      "====> Epoch: 39 Average loss: 170.5229\n",
      "====> Test set loss: 171.0268\n",
      "====> Epoch: 40 Average loss: 170.3744\n",
      "====> Test set loss: 170.5922\n",
      "====> Epoch: 41 Average loss: 170.2706\n",
      "====> Test set loss: 171.2749\n",
      "====> Epoch: 42 Average loss: 170.3026\n",
      "====> Test set loss: 170.5592\n",
      "====> Epoch: 43 Average loss: 170.2308\n",
      "====> Test set loss: 170.1042\n",
      "====> Epoch: 44 Average loss: 170.1228\n",
      "====> Test set loss: 170.3709\n",
      "====> Epoch: 45 Average loss: 170.1934\n",
      "====> Test set loss: 170.9855\n",
      "====> Epoch: 46 Average loss: 170.0920\n",
      "====> Test set loss: 170.0914\n",
      "====> Epoch: 47 Average loss: 170.0682\n",
      "====> Test set loss: 170.2791\n",
      "====> Epoch: 48 Average loss: 170.0343\n",
      "====> Test set loss: 170.3585\n",
      "====> Epoch: 49 Average loss: 169.9267\n",
      "====> Test set loss: 169.9278\n",
      "====> Epoch: 50 Average loss: 169.9634\n",
      "====> Test set loss: 170.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kadarsh22/miniconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "#             save_image(sample.view(64, 1, 28, 28),\n",
    "# 'results/sample_' + str(epoch) + '.png')\n",
    "torch.save(model,'vae_beta8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= torch.load('vae_beta8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(60000,20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 5.61 GiB (GPU 0; 31.72 GiB total capacity; 10.03 GiB already allocated; 3.89 GiB free; 8.05 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-88d47f241d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-27b1309e281d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdeconv_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeconv_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# print(\"deconv_input\", deconv_input.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeconv_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreparametrize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    756\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.61 GiB (GPU 0; 31.72 GiB total capacity; 10.03 GiB already allocated; 3.89 GiB free; 8.05 MiB cached)"
     ]
    }
   ],
   "source": [
    "images = model.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_wgan_loader = list(torch.split(images.to(device),1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../model_files/')\n",
    "from lenet import Lenet\n",
    "from Custom_Dataset import NewDataset\n",
    "full_cnn_model = Lenet()\n",
    "full_cnn_model.load_state_dict(torch.load('../../trained_models/cnn_lenet_28_sigmoid.pt',map_location='cuda:0'))\n",
    "full_cnn_model.eval()\n",
    "full_cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = []\n",
    "for images_new in mnist_wgan_loader:\n",
    "    out = F.softmax(full_cnn_model(images_new),dim=1)\n",
    "    _,labels = torch.max(out.data.cpu(), 1)\n",
    "    labels_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  torch.stack(labels_list).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(images[:50].detach().cpu(), nrow= 10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "labels[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = NewDataset(images,labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_dataset = dsets.MNIST(root='./newminst_wgan', \n",
    "                           train=False, \n",
    "                           transform=transform,download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 22\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(seed )\n",
    "torch.cuda.manual_seed(seed )\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cnn_model = Lenet()\n",
    "full_cnn_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(full_cnn_model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(60):\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    full_cnn_model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = full_cnn_model (images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "    \n",
    "    full_cnn_model.eval()\n",
    "    accuracy_list = []\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        outputs = full_cnn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = labels.size(0)\n",
    "        correct = (predicted == labels).sum()\n",
    "        accuracy = 100 * (float(correct) /float( total))\n",
    "        accuracy_list.append(accuracy)\n",
    "        test_loss_list.append(loss.item())\n",
    "    final_accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "    traininig_loss = sum(train_loss_list)/len(train_loss_list)\n",
    "    testing_loss = sum(test_loss_list)/len(test_loss_list)\n",
    "    print('Epoch: {}. TrainLoss: {}. TestLoss: {}. Accuracy: {}'.format(epoch, traininig_loss,testing_loss, final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "def visualise_disentaglement(data):\n",
    "    viz = visdom.Visdom()\n",
    "    samples = []\n",
    "    limit=5\n",
    "    inter = 2/3\n",
    "    num = 1\n",
    "    interpolation = torch.arange(-limit, limit+0.1, inter)\n",
    "    \n",
    "    train_data = torch.utils.data.DataLoader(data,batch_size=128,shuffle=True)\n",
    "    images = iter(train_data).next()\n",
    "    images = images[0:num,:,:]\n",
    "    images  = Variable(images.to(device))\n",
    "    z_mean,z_std = model.encode(images)\n",
    "    for i in range(num):\n",
    "        z_orginal = z_mean\n",
    "        for j in range(20):\n",
    "            temp = z_mean.data[:,j].clone()\n",
    "            for k in interpolation:\n",
    "                z_orginal.data[:,j]= k\n",
    "                sample = model.decode(z_orginal)\n",
    "                sample = F.sigmoid(sample)\n",
    "                sample = sample.view(-1,1,28,28)\n",
    "                samples.append(sample)\n",
    "            z_orginal.data[:,j] = temp\n",
    "    samp = torch.cat(samples, dim=0).cpu() \n",
    "    viz.images(samp, env='_traverse',opts=dict(colormap='gray'), nrow=len(interpolation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = visualise_disentaglement(x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
